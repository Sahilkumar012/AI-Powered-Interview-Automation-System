# -*- coding: utf-8 -*-
"""Tf_idf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UuXdQMNCespNq3Ol8A99GvvZDtTZnWL9
"""

import pandas as pd  # ✅ Fix added here — required for pd.read_csv below

def main():
    import pandas as pd
    import numpy as np
    import re
    import string

from sklearn.preprocessing import LabelEncoder
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

df = pd.read_csv('UpdatedResumeDataSet.csv', encoding='ISO-8859-1')

print(df.columns.tolist())

df = df[['Category', 'Resume']]    # Ensure only required columns

df.head()

df.tail()

import re
import string
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text_advanced(text):
    # Lowercase
    text = text.lower()

    # Remove non-ASCII characters (like 芒垄 etc.)
    text = text.encode('ascii', 'ignore').decode()

    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Tokenize
    tokens = text.split()

    # Remove stopwords and non-alphabetic words
    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]

    # Lemmatize
    tokens = [lemmatizer.lemmatize(word) for word in tokens]

    # Join back
    return " ".join(tokens)

df['cleaned_resume'] = df['Resume'].apply(clean_text_advanced)

le = LabelEncoder()
df['encoded_category'] = le.fit_transform(df['Category'])

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=3000)
X = vectorizer.fit_transform(df['cleaned_resume'])
y = df['encoded_category']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Final DataFrame with required columns
final_df = df[['Category', 'encoded_category', 'cleaned_resume']]

final_df.to_csv('preprocessed_resumes.csv', index=False)

# from google.colab import files
# files.download('preprocessed_resumes.csv')

"""**Preprocessed End**

***NLP Start***
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
import numpy as np

# Assuming df['cleaned_resume'] already exists
vectorizer = TfidfVectorizer(max_features=3000)  # you can change max_features
tfidf_matrix = vectorizer.fit_transform(df['cleaned_resume'])

# Convert to DataFrame (optional)
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())

def get_top_keywords(row_vector, feature_names, top_n=10):
    sorted_indices = row_vector.argsort()[::-1][:top_n]
    top_features = [(feature_names[i], row_vector[i]) for i in sorted_indices]
    return [word for word, score in top_features]

top_keywords = []
feature_names = vectorizer.get_feature_names_out()

for i in range(tfidf_matrix.shape[0]):
    row_vector = tfidf_matrix[i].toarray().flatten()
    keywords = get_top_keywords(row_vector, feature_names, top_n=10)
    top_keywords.append(", ".join(keywords))

df['top_keywords'] = top_keywords

df.to_csv('resume_with_keywords_TF-IDF_main.csv', index=False)

"""**below code is giving accuracy al most 0.99**"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


# Load cleaned data again if needed
df = df.drop_duplicates(subset='cleaned_resume')  # Remove duplicates if not already

vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=3000)

# TF-IDF vectorization with filters
vectorizer = TfidfVectorizer(max_features=3000, min_df=5, max_df=0.85)
X = vectorizer.fit_transform(df['cleaned_resume'])
y = df['encoded_category']

# Logistic Regression with class weight balance
# model = LogisticRegression(max_iter=1000, class_weight='balanced')

# model = RandomForestClassifier(n_estimators=100, class_weight='balanced')

model = SVC(kernel='linear', class_weight='balanced')

# 5-fold cross-validation
scores = cross_val_score(model, X, y, cv=5)

# Output accuracy
print("TF-IDF Accuracy:", round(scores.mean() * 100, 2), "%")
print("Fold-wise Accuracies:", np.round(scores * 100, 2))
plt.figure(figsize=(4, 3))
plt.plot(range(1, 6), scores * 100, marker='o', linestyle='--', color='b')
plt.title('5-Fold Cross-Validation Accuracy')
plt.xlabel('Fold')
plt.ylabel('Accuracy (%)')
plt.ylim(0, 100)
plt.grid(True)
plt.xticks(range(1, 6))
plt.tight_layout()
plt.show()


